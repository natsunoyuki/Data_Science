{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNTQmHVw6ehqqvpWvUk34aX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# CTC Loss with OCR\n","\n","References\n","* https://en.wikipedia.org/wiki/Connectionist_temporal_classification\n","* https://keras.io/examples/vision/captcha_ocr/#model\n","* https://distill.pub/2017/ctc/"],"metadata":{"id":"_P-jXkdBKioQ"}},{"cell_type":"code","source":["# https://jref.com/resources/ms-gothic.53/\n","#!wget https://jref.com/resources/ms-gothic.53/download\n","#!unzip msgothic.zip"],"metadata":{"id":"nLJt5Wg32AcB","executionInfo":{"status":"ok","timestamp":1662474603365,"user_tz":-540,"elapsed":612,"user":{"displayName":"Yuki Natsume","userId":"12150857735362412716"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":27,"metadata":{"id":"RwWR8UjyOj-i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662475844781,"user_tz":-540,"elapsed":14,"user":{"displayName":"Yuki Natsume","userId":"12150857735362412716"}},"outputId":"141f9d6c-143f-4d48-baab-57a4b3c7084a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","from PIL import Image, ImageDraw, ImageFont\n","import tensorflow as tf\n","from difflib import SequenceMatcher\n","\n","try:\n","    DEVICE_NAME = tf.test.gpu_device_name()\n","    print(\"Found GPU at: {}\".format(DEVICE_NAME))\n","except:\n","    DEVICE_NAME = \"/device:CPU:0\"\n","    print(\"ERROR: Not connected to a GPU runtime.\")"]},{"cell_type":"code","source":["# Make train-valid-test splits of images and labels.\n","N_train = 10000\n","N_valid = 2000\n","N_test = 2000\n","\n","# Image dimensions.\n","height = 32\n","width = 256\n","\n","# Character list used to create the data.\n","#chars = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n","#chars = \"アイウエオカキクケコサシスセソタチツテトナニヌネノハヒフヘホマミムメモヤユヨラリルレロワヲン\"\n","chars = \"ｱｲｳｴｵｶｷｸｹｺｻｼｽｾｿﾀﾁﾂﾃﾄﾅﾆﾇﾈﾉﾊﾋﾌﾍﾎﾏﾐﾑﾒﾓﾔﾕﾖﾗﾘﾙﾚﾛﾜｦﾝ\"\n","\n","chars = sorted([c for c in chars])\n","\n","# Character to index map and reverse map.\n","char_to_ind = tf.keras.layers.StringLookup(vocabulary = list(chars), mask_token = None)\n","ind_to_char = tf.keras.layers.StringLookup(vocabulary = char_to_ind.get_vocabulary(), mask_token = None, invert = True)\n","\n","#font = ImageFont.truetype(\"Humor-Sans.ttf\", 24)\n","font = ImageFont.truetype(\"./msgothic.ttc\", 24)"],"metadata":{"id":"XjPJXn6YymjU","executionInfo":{"status":"ok","timestamp":1662474686208,"user_tz":-540,"elapsed":607,"user":{"displayName":"Yuki Natsume","userId":"12150857735362412716"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def make_data(N_samples, min_len = 4, max_len = 10, engine = \"cv2\"):\n","    X = []\n","    y = []\n","    # Create N_samples samples of features X and labels y.\n","    for i in range(N_samples):\n","        # Each image contains randomly generated text with random length [4, 10].\n","        N = np.random.randint(min_len, max_len + 1)\n","        text = np.random.choice(chars, N)\n","\n","        text = \"\".join(text)\n","\n","        # Randomly jitter the position of the text in the image.\n","        # Do not jitter the y coordinate! Only the x-coordinate (i.e. the time coordinate)\n","        # should be jittered.\n","        if engine == \"cv2\":\n","            image = np.zeros([height, width])\n","            anchor = (0 + np.random.randint(0, 122 + (max_len - len(text)) * 12), 22)\n","            image = cv2.putText(image, text, anchor, cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv2.LINE_AA)\n","        elif engine == \"pil\":\n","            anchor = (0 + np.random.randint(0, 122 + (max_len - len(text)) * 12), 5)\n","            image = Image.new(\"RGB\", [width, height], (0, 0, 0))\n","            d = ImageDraw.Draw(image)\n","            d.text(anchor, text, font = font, fill = (255, 255, 255), anchor = \"lm\")\n","            image = np.array(image)\n","            image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n","\n","        X.append(image.reshape((height, width, 1)))\n","        # Make all texts the same length (i.e. max_len). \n","        # Also ensure no white space before text.\n","        # These spaces will be converted to zeros by the encoder. \n","        text = text.strip()\n","        pad = (max_len - len(text)) * \" \"\n","        y.append(text + pad)\n","\n","    return X, y"],"metadata":{"id":"NQQrVh2oO90X","executionInfo":{"status":"ok","timestamp":1662474686645,"user_tz":-540,"elapsed":19,"user":{"displayName":"Yuki Natsume","userId":"12150857735362412716"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["engine = \"pil\"\n","\n","X_train, y_train = make_data(N_train, engine = engine)\n","X_valid, y_valid = make_data(N_valid, engine = engine)\n","X_test, y_test = make_data(N_test, engine = engine)\n","\n","X_train = np.array(X_train)\n","y_train = np.array(y_train)\n","X_valid = np.array(X_valid)\n","y_valid = np.array(y_valid)\n","X_test = np.array(X_test)\n","y_test = np.array(y_test)"],"metadata":{"id":"9i--Dum0ysAw","executionInfo":{"status":"ok","timestamp":1662474694837,"user_tz":-540,"elapsed":8206,"user":{"displayName":"Yuki Natsume","userId":"12150857735362412716"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["#plt.figure(figsize = (20, 5))\n","#for i in range(10):\n","#    plt.subplot(2, 5, i+1)\n","#    plt.imshow(X_train[i][:, :, 0], cmap = \"binary\")\n","#    plt.title(y_train[i])\n","#plt.show()"],"metadata":{"id":"XAczRGdCSwbp","executionInfo":{"status":"ok","timestamp":1662474793399,"user_tz":-540,"elapsed":14,"user":{"displayName":"Yuki Natsume","userId":"12150857735362412716"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["batch_size = 20\n","def encode_data(image, label):\n","    image = tf.keras.layers.Rescaling(1.0 / 255)(image)\n","    image = tf.transpose(image, perm = [1, 0, 2])\n","    label = char_to_ind(tf.strings.unicode_split(label,\n","                                input_encoding = \"UTF-8\"))\n","    return {\"image\": image, \"label\": label}\n","\n","with tf.device(DEVICE_NAME):\n","    train_ds = tf.data.Dataset.from_tensor_slices((X_train,\n","                                                   y_train))\n","    train_ds = train_ds.map(encode_data,\n","               num_parallel_calls = tf.data.AUTOTUNE)\n","    train_ds = train_ds.batch(batch_size)\n","    train_ds = train_ds.prefetch(buffer_size = tf.data.AUTOTUNE)\n","    valid_ds = tf.data.Dataset.from_tensor_slices((X_valid,\n","                                                   y_valid))\n","    valid_ds = valid_ds.map(encode_data,\n","               num_parallel_calls = tf.data.AUTOTUNE)\n","    valid_ds = valid_ds.batch(batch_size)\n","    valid_ds = valid_ds.prefetch(buffer_size = tf.data.AUTOTUNE)\n","    test_ds = tf.data.Dataset.from_tensor_slices((X_test,\n","                                                  y_test))\n","    test_ds = test_ds.map(encode_data,\n","              num_parallel_calls = tf.data.AUTOTUNE)\n","    test_ds = test_ds.batch(batch_size)\n","    test_ds = test_ds.prefetch(buffer_size = tf.data.AUTOTUNE)"],"metadata":{"id":"I4mzrcEJUC8V","executionInfo":{"status":"ok","timestamp":1662474849346,"user_tz":-540,"elapsed":972,"user":{"displayName":"Yuki Natsume","userId":"12150857735362412716"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["class CTCLayer(tf.keras.layers.Layer):\n","    def __init__(self, name = None):\n","        super().__init__(name = name)\n","        self.loss_fn = tf.keras.backend.ctc_batch_cost\n","\n","    def call(self, y_true, y_pred):\n","        batch_len = tf.cast(tf.shape(y_true)[0], dtype = \"int64\")\n","        input_length = tf.cast(tf.shape(y_pred)[1], dtype = \"int64\")\n","        input_length = input_length * tf.ones(shape = (batch_len, 1), dtype = \"int64\")\n","        label_length = tf.cast(tf.shape(y_true)[1], dtype = \"int64\")\n","        label_length = label_length * tf.ones(shape = (batch_len, 1), dtype = \"int64\")\n","        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n","        self.add_loss(loss)\n","        return y_pred\n","\n","def make_model():\n","    input_img = tf.keras.layers.Input(shape = (width, height, 1), name = \"image\", dtype = \"float32\")\n","    labels = tf.keras.layers.Input(name = \"label\", shape = (None,), dtype = \"float32\")\n","\n","    x = tf.keras.layers.Conv2D(32, (3, 3), activation = \"relu\", kernel_initializer = \"he_normal\",\n","                               padding = \"same\", name = \"Conv1\")(input_img)\n","    x = tf.keras.layers.MaxPooling2D((2, 2), name = \"pool1\")(x)\n","\n","    x = tf.keras.layers.Conv2D(64, (3, 3), activation = \"relu\", kernel_initializer = \"he_normal\",\n","                               padding = \"same\", name = \"Conv2\")(x)\n","    x = tf.keras.layers.MaxPooling2D((2, 2), name = \"pool2\")(x)\n","\n","    new_shape = ((width // 4), (height // 4) * 64)\n","    x = tf.keras.layers.Reshape(target_shape = new_shape, name = \"reshape\")(x)\n","    x = tf.keras.layers.Dense(64, activation = \"relu\", name = \"dense1\")(x)\n","    x = tf.keras.layers.Dropout(0.2)(x)\n","\n","    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences = True, dropout = 0.25))(x)\n","    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences = True, dropout = 0.25))(x)\n","\n","    x = tf.keras.layers.Dense(len(char_to_ind.get_vocabulary()) + 1, activation = \"softmax\", name = \"dense2\")(x)\n","\n","    output = CTCLayer(name = \"ctc_loss\")(labels, x)\n","\n","    model = tf.keras.models.Model(inputs = [input_img, labels], outputs = output, name = \"ocr_model_v1\")\n","    opt = tf.keras.optimizers.Adam()\n","    model.compile(optimizer = opt)\n","    return model\n","\n","# Get the model\n","with tf.device(DEVICE_NAME):\n","    model = make_model()"],"metadata":{"id":"TByWzBw0aCgw","executionInfo":{"status":"ok","timestamp":1662474855079,"user_tz":-540,"elapsed":3028,"user":{"displayName":"Yuki Natsume","userId":"12150857735362412716"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["epochs = 20\n","\n","history = model.fit(train_ds, validation_data = valid_ds, epochs = epochs)"],"metadata":{"id":"DNuecA5_bJqk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662475284895,"user_tz":-540,"elapsed":429830,"user":{"displayName":"Yuki Natsume","userId":"12150857735362412716"}},"outputId":"ccf7bced-d9ec-4646-d8ff-5cb8367f9e16"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","500/500 [==============================] - 40s 44ms/step - loss: 31.8063 - val_loss: 28.9197\n","Epoch 2/20\n","500/500 [==============================] - 19s 39ms/step - loss: 28.9125 - val_loss: 28.5553\n","Epoch 3/20\n","500/500 [==============================] - 19s 37ms/step - loss: 27.4633 - val_loss: 16.6775\n","Epoch 4/20\n","500/500 [==============================] - 19s 37ms/step - loss: 5.4609 - val_loss: 1.7413\n","Epoch 5/20\n","500/500 [==============================] - 19s 37ms/step - loss: 1.6183 - val_loss: 1.2514\n","Epoch 6/20\n","500/500 [==============================] - 19s 37ms/step - loss: 0.9575 - val_loss: 0.4656\n","Epoch 7/20\n","500/500 [==============================] - 19s 37ms/step - loss: 0.4663 - val_loss: 0.3263\n","Epoch 8/20\n","500/500 [==============================] - 19s 37ms/step - loss: 0.3654 - val_loss: 0.2789\n","Epoch 9/20\n","500/500 [==============================] - 19s 37ms/step - loss: 0.2926 - val_loss: 0.2219\n","Epoch 10/20\n","500/500 [==============================] - 19s 39ms/step - loss: 0.2463 - val_loss: 0.2138\n","Epoch 11/20\n","500/500 [==============================] - 19s 38ms/step - loss: 0.2139 - val_loss: 0.1834\n","Epoch 12/20\n","500/500 [==============================] - 19s 38ms/step - loss: 0.2234 - val_loss: 0.1843\n","Epoch 13/20\n","500/500 [==============================] - 19s 37ms/step - loss: 0.1843 - val_loss: 0.1910\n","Epoch 14/20\n","500/500 [==============================] - 18s 36ms/step - loss: 0.1493 - val_loss: 0.1647\n","Epoch 15/20\n","500/500 [==============================] - 18s 37ms/step - loss: 0.1380 - val_loss: 0.1775\n","Epoch 16/20\n","500/500 [==============================] - 18s 37ms/step - loss: 0.1421 - val_loss: 0.1357\n","Epoch 17/20\n","500/500 [==============================] - 18s 37ms/step - loss: 0.1180 - val_loss: 0.1624\n","Epoch 18/20\n","500/500 [==============================] - 18s 37ms/step - loss: 0.1282 - val_loss: 0.1621\n","Epoch 19/20\n","500/500 [==============================] - 19s 38ms/step - loss: 0.1013 - val_loss: 0.3659\n","Epoch 20/20\n","500/500 [==============================] - 18s 37ms/step - loss: 0.0935 - val_loss: 0.1492\n"]}]},{"cell_type":"code","source":["# Get the prediction model by extracting layers till the output layer\n","prediction_model = tf.keras.models.Model(model.get_layer(name = \"image\").input, \n","                                         model.get_layer(name = \"dense2\").output)\n","\n","max_length = 10\n","\n","# A utility function to decode the output of the network\n","def decode_batch_predictions(pred):\n","    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n","    # Use greedy search. For complex tasks, you can use beam search\n","    results = tf.keras.backend.ctc_decode(pred, input_length = input_len, greedy = True)[0][0][:, :max_length]\n","    # Iterate over the results and get back the text\n","    output_text = []\n","    for res in results:\n","        res = tf.strings.reduce_join(ind_to_char(res)).numpy().decode(\"utf-8\")\n","        output_text.append(res)\n","    return output_text"],"metadata":{"id":"5mNmXm20cHJg","executionInfo":{"status":"ok","timestamp":1662475560199,"user_tz":-540,"elapsed":253,"user":{"displayName":"Yuki Natsume","userId":"12150857735362412716"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["y_pred = []\n","y_true = []\n","\n","for batch in test_ds:\n","    batch_images = batch[\"image\"]\n","    batch_labels = batch[\"label\"]\n","\n","    preds = prediction_model.predict(batch_images)\n","    pred_texts = decode_batch_predictions(preds)\n","    y_pred = y_pred + pred_texts\n","\n","    orig_texts = []\n","    for label in batch_labels:\n","        label = tf.strings.reduce_join(ind_to_char(label)).numpy().decode(\"utf-8\")\n","        orig_texts.append(label)\n","    y_true = y_true + orig_texts\n","\n","#    _, ax = plt.subplots(5, 4, figsize = (20, 10))\n","#    for i in range(len(pred_texts)):\n","#        img = (batch_images[i, :, :, 0] * 255).numpy().astype(np.uint8)\n","#        img = img.T\n","#        title = \"{}\".format(pred_texts[i])\n","#        ax[i // 4, i % 4].imshow(img, cmap = \"binary\")\n","#        ax[i // 4, i % 4].set_title(title)\n","#plt.show()"],"metadata":{"id":"_TryMuvznM-H","executionInfo":{"status":"ok","timestamp":1662475776068,"user_tz":-540,"elapsed":11248,"user":{"displayName":"Yuki Natsume","userId":"12150857735362412716"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["def similarity(x, y):\n","    return SequenceMatcher(None, x, y).ratio()\n","\n","similarities = np.array([0] * len(y_true))\n","\n","for i in range(len(y_true)):\n","    similarities[i] = similarity(y_true[i], y_pred[i])"],"metadata":{"id":"yau98jPj6GTT","executionInfo":{"status":"ok","timestamp":1662476011636,"user_tz":-540,"elapsed":9,"user":{"displayName":"Yuki Natsume","userId":"12150857735362412716"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["print(np.mean(similarities))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_4zg4yMVRbi2","executionInfo":{"status":"ok","timestamp":1662476011938,"user_tz":-540,"elapsed":16,"user":{"displayName":"Yuki Natsume","userId":"12150857735362412716"}},"outputId":"93797ac6-89cc-43e3-935c-35710aa70dcb"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9855\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"0ga8d2MySmNm"},"execution_count":null,"outputs":[]}]}