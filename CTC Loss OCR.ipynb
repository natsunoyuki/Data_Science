{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO26lZpg51JgHR/ih031+Hf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# CTC Loss with OCR\n","\n","References\n","* https://en.wikipedia.org/wiki/Connectionist_temporal_classification\n","* https://keras.io/examples/vision/captcha_ocr/#model\n","* https://distill.pub/2017/ctc/"],"metadata":{"id":"_P-jXkdBKioQ"}},{"cell_type":"code","source":["#!wget -P /usr/share/fonts/truetype https://github.com/Dangetsu/vnr/blob/master/Fonts/msgothic.ttf\n","#!wget https://fonts.google.com/download?family=Noto%20Serif%20JP\n","#!unzip \"./Noto_Serif_JP.zip\""],"metadata":{"id":"nLJt5Wg32AcB"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RwWR8UjyOj-i"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","from PIL import Image, ImageDraw, ImageFont\n","import tensorflow as tf\n","\n","try:\n","    DEVICE_NAME = tf.test.gpu_device_name()\n","    print(\"Found GPU at: {}\".format(DEVICE_NAME))\n","except:\n","    DEVICE_NAME = \"/device:CPU:0\"\n","    print(\"ERROR: Not connected to a GPU runtime.\")"]},{"cell_type":"code","source":["# Make train-valid-test splits of images and labels.\n","N_train = 10000\n","N_valid = 2000\n","N_test = 2000\n","\n","# Image dimensions.\n","height = 32\n","width = 256\n","\n","# Character list used to create the data.\n","chars = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n","#chars = \"アイウエオカキクケコサシスセソタチツテトナニヌネノハヒフヘホマミムメモヤユヨラリルレロワヲン\"\n","#chars = \"ｱｲｳｴｵｶｷｸｹｺｻｼｽｾｿﾀﾁﾂﾃﾄﾅﾆﾇﾈﾉﾊﾋﾌﾍﾎﾏﾐﾑﾒﾓﾔﾕﾖﾗﾘﾙﾚﾛﾜｦﾝ\"\n","\n","chars = sorted([c for c in chars])\n","\n","# Character to index map and reverse map.\n","char_to_num = tf.keras.layers.StringLookup(vocabulary = list(chars), mask_token = None)\n","num_to_char = tf.keras.layers.StringLookup(vocabulary = char_to_num.get_vocabulary(), mask_token = None, invert = True)\n","\n","font = ImageFont.truetype(\"Humor-Sans.ttf\", 24)"],"metadata":{"id":"XjPJXn6YymjU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def make_data(N_samples, min_len = 4, max_len = 10, engine = \"cv2\"):\n","    X = []\n","    y = []\n","    # Create N_samples samples of features X and labels y.\n","    for i in range(N_samples):\n","        # Each image contains randomly generated text with random length [4, 10].\n","        N = np.random.randint(min_len, max_len + 1)\n","        text = np.random.choice(chars, N)\n","\n","        text = \"\".join(text)\n","\n","        # Randomly jitter the position of the text in the image.\n","        # Do not jitter the y coordinate! Only the x-coordinate (i.e. the time coordinate)\n","        # should be jittered.\n","        if engine == \"cv2\":\n","            image = np.zeros([height, width])\n","            anchor = (0 + np.random.randint(0, 122 + (max_len - len(text)) * 12), 22)\n","            image = cv2.putText(image, text, anchor, cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv2.LINE_AA)\n","        elif engine == \"pil\":\n","            anchor = (0 + np.random.randint(0, 122 + (max_len - len(text)) * 12), 5)\n","            image = Image.new(\"RGB\", [width, height], (0, 0, 0))\n","            d = ImageDraw.Draw(image)\n","            d.text(anchor, text, font = font, fill = (255, 255, 255), anchor = \"lm\")\n","            image = np.array(image)\n","            image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n","\n","        X.append(image.reshape((height, width, 1)))\n","        # Make all texts the same length (i.e. max_len). \n","        # Also ensure no white space before text.\n","        # These spaces will be converted to zeros by the encoder. \n","        text = text.strip()\n","        pad = (max_len - len(text)) * \" \"\n","        y.append(text + pad)\n","\n","    return X, y"],"metadata":{"id":"NQQrVh2oO90X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["engine = \"cv2\"\n","\n","X_train, y_train = make_data(N_train, engine = engine)\n","X_valid, y_valid = make_data(N_valid, engine = engine)\n","X_test, y_test = make_data(N_test, engine = engine)\n","\n","X_train = np.array(X_train)\n","y_train = np.array(y_train)\n","X_valid = np.array(X_valid)\n","y_valid = np.array(y_valid)\n","X_test = np.array(X_test)\n","y_test = np.array(y_test)"],"metadata":{"id":"9i--Dum0ysAw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize = (20, 5))\n","for i in range(10):\n","    plt.subplot(2, 5, i+1)\n","    plt.imshow(X_train[i][:, :, 0], cmap = \"binary\")\n","    plt.title(y_train[i])\n","plt.show()"],"metadata":{"id":"XAczRGdCSwbp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 20\n","\n","def encode_single_sample(X, y):\n","    X = tf.keras.layers.Rescaling(1.0 / 255)(X)\n","    X = tf.transpose(X, perm = [1, 0, 2])\n","    y = char_to_num(tf.strings.unicode_split(y, input_encoding = \"UTF-8\"))\n","    return {\"image\": X, \"label\": y}\n","\n","with tf.device(DEVICE_NAME):\n","    train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n","    train_ds = (train_ds.map(encode_single_sample, \n","                             num_parallel_calls = tf.data.AUTOTUNE).batch(batch_size).prefetch(buffer_size = tf.data.AUTOTUNE))\n","\n","    valid_ds = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n","    valid_ds = (valid_ds.map(encode_single_sample, \n","                             num_parallel_calls = tf.data.AUTOTUNE).batch(batch_size).prefetch(buffer_size = tf.data.AUTOTUNE))\n","\n","    test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n","    test_ds = (test_ds.map(encode_single_sample, \n","                           num_parallel_calls = tf.data.AUTOTUNE).batch(batch_size).prefetch(buffer_size = tf.data.AUTOTUNE))"],"metadata":{"id":"I4mzrcEJUC8V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CTCLayer(tf.keras.layers.Layer):\n","    def __init__(self, name = None):\n","        super().__init__(name = name)\n","        self.loss_fn = tf.keras.backend.ctc_batch_cost\n","\n","    def call(self, y_true, y_pred):\n","        batch_len = tf.cast(tf.shape(y_true)[0], dtype = \"int64\")\n","        input_length = tf.cast(tf.shape(y_pred)[1], dtype = \"int64\")\n","        label_length = tf.cast(tf.shape(y_true)[1], dtype = \"int64\")\n","\n","        input_length = input_length * tf.ones(shape = (batch_len, 1), dtype = \"int64\")\n","        label_length = label_length * tf.ones(shape = (batch_len, 1), dtype = \"int64\")\n","\n","        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n","        self.add_loss(loss)\n","        return y_pred\n","\n","\n","def build_model():\n","    input_img = tf.keras.layers.Input(shape = (width, height, 1), name = \"image\", dtype = \"float32\")\n","    labels = tf.keras.layers.Input(name = \"label\", shape = (None,), dtype = \"float32\")\n","\n","    x = tf.keras.layers.Conv2D(32, (3, 3), activation = \"relu\", kernel_initializer = \"he_normal\",\n","                               padding = \"same\", name = \"Conv1\")(input_img)\n","    x = tf.keras.layers.MaxPooling2D((2, 2), name = \"pool1\")(x)\n","\n","    x = tf.keras.layers.Conv2D(64, (3, 3), activation = \"relu\", kernel_initializer = \"he_normal\",\n","                               padding = \"same\", name = \"Conv2\")(x)\n","    x = tf.keras.layers.MaxPooling2D((2, 2), name = \"pool2\")(x)\n","\n","    new_shape = ((width // 4), (height // 4) * 64)\n","    x = tf.keras.layers.Reshape(target_shape = new_shape, name = \"reshape\")(x)\n","    x = tf.keras.layers.Dense(64, activation = \"relu\", name = \"dense1\")(x)\n","    x = tf.keras.layers.Dropout(0.2)(x)\n","\n","    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences = True, dropout = 0.25))(x)\n","    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences = True, dropout = 0.25))(x)\n","\n","    x = tf.keras.layers.Dense(len(char_to_num.get_vocabulary()) + 1, activation = \"softmax\", name = \"dense2\")(x)\n","\n","    output = CTCLayer(name = \"ctc_loss\")(labels, x)\n","\n","    model = tf.keras.models.Model(inputs = [input_img, labels], outputs = output, name = \"ocr_model_v1\")\n","    opt = tf.keras.optimizers.Adam()\n","    model.compile(optimizer = opt)\n","    return model\n","\n","\n","# Get the model\n","with tf.device(DEVICE_NAME):\n","    model = build_model()"],"metadata":{"id":"TByWzBw0aCgw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 20\n","\n","history = model.fit(train_ds, validation_data = valid_ds, epochs = epochs)"],"metadata":{"id":"DNuecA5_bJqk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the prediction model by extracting layers till the output layer\n","prediction_model = tf.keras.models.Model(model.get_layer(name = \"image\").input, model.get_layer(name = \"dense2\").output)\n","prediction_model.summary()\n","\n","max_length = 10\n","\n","# A utility function to decode the output of the network\n","def decode_batch_predictions(pred):\n","    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n","    # Use greedy search. For complex tasks, you can use beam search\n","    results = tf.keras.backend.ctc_decode(pred, input_length = input_len, greedy = True)[0][0][:, :max_length]\n","    # Iterate over the results and get back the text\n","    output_text = []\n","    for res in results:\n","        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n","        output_text.append(res)\n","    return output_text"],"metadata":{"id":"5mNmXm20cHJg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for batch in test_ds.take(1):\n","    batch_images = batch[\"image\"]\n","    batch_labels = batch[\"label\"]\n","\n","    preds = prediction_model.predict(batch_images)\n","    pred_texts = decode_batch_predictions(preds)\n","\n","    orig_texts = []\n","    for label in batch_labels:\n","        label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n","        orig_texts.append(label)\n","\n","    _, ax = plt.subplots(5, 4, figsize = (20, 10))\n","    for i in range(len(pred_texts)):\n","        img = (batch_images[i, :, :, 0] * 255).numpy().astype(np.uint8)\n","        img = img.T\n","        title = \"{}\".format(pred_texts[i])\n","        ax[i // 4, i % 4].imshow(img, cmap = \"binary\")\n","        ax[i // 4, i % 4].set_title(title)\n","plt.show()"],"metadata":{"id":"_TryMuvznM-H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"FLoaZBh4rzDI"},"execution_count":null,"outputs":[]}]}