{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# PyTorch Faster R-CNN\n","\n","### Torch and TorchVision\n","https://pytorch.org/vision/stable/models/generated/torchvision.models.detection.fasterrcnn_resnet50_fpn.html#torchvision.models.detection.fasterrcnn_resnet50_fpn\n","\n","https://pytorch.org/vision/stable/training_references.html\n","\n","### COCO Images\n","https://cocodataset.org/#home\n","\n","https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocoDemo.ipynb"],"metadata":{"id":"dbeDvCONy6Uw"}},{"cell_type":"code","source":["import os\n","import time\n","import datetime\n","import shutil\n","\n","from collections import defaultdict\n","\n","from pycocotools.coco import COCO\n","\n","import PIL\n","import cv2\n","\n","import numpy as np\n","import skimage.io as io\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","\n","import tqdm\n","\n","from sklearn.model_selection import train_test_split\n","\n","import torch\n","import torchvision\n","from torchvision.models.detection import fasterrcnn_resnet50_fpn\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","\n","try:\n","    from torchmetrics.detection.mean_ap import MeanAveragePrecision\n","except:\n","    !pip install torchmetrics\n","    from torchmetrics.detection.mean_ap import MeanAveragePrecision\n","\n","import albumentations as A \n","from albumentations.pytorch import ToTensorV2\n","\n","date = str(datetime.date.today())\n","\n","if torch.cuda.is_available():\n","    device_name = torch.device(\"cuda\")\n","else:\n","    device_name = torch.device(\"cpu\")\n","     \n","print(\"Using {}.\".format(device_name));"],"metadata":{"id":"R-zbTXOy04OX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Download and Prepare COCO Images and Annotations"],"metadata":{"id":"EvQvtyi22qPs"}},{"cell_type":"code","source":["# Download image files.\n","#if \"train2017.zip\" not in os.listdir(\"./\"):\n","#    !wget http://images.cocodataset.org/zips/train2017.zip\n","#    !unzip train.zip"],"metadata":{"id":"0PBzsdfx5kyL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Download annotations files.\n","if \"annotations_trainval2017.zip\" not in os.listdir(\"./\"):\n","    !wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n","    !unzip annotations_trainval2017.zip"],"metadata":{"id":"8cnMpbKay4mO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the train and val annotations into memory.\n","train_ann_file = \"./annotations/instances_{}.json\".format(\"train2017\")\n","val_ann_file = \"./annotations/instances_{}.json\".format(\"val2017\")\n","\n","train_coco = COCO(train_ann_file)\n","val_coco = COCO(val_ann_file)"],"metadata":{"id":"S-tcZEXSy4tq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class COCO(torch.utils.data.Dataset):\n","    def __init__(self, coco, wanted_classes = [\"person\"], transforms = None):\n","        self.coco = coco\n","        self.cat_ids = self.coco.getCatIds(catNms = wanted_classes)\n","        self.img_ids = self.coco.getImgIds(catIds = self.cat_ids)\n","        self.coco_dicts = self.coco.loadImgs(self.img_ids)\n","        self.transforms = transforms\n","        \n","    def __getitem__(self, i):\n","        # Obtain the image from the internet.\n","        image = io.imread(self.coco_dicts[i].get(\"coco_url\"))\n","\n","        # Bounding boxes in MS COCO format.\n","        ann_ids = self.coco.getAnnIds(imgIds = self.coco_dicts[i].get(\"id\"), catIds = self.cat_ids, iscrowd = None)\n","        anns = self.coco.loadAnns(ann_ids)\n","\n","        target = {\"bboxes\" : np.array([a.get(\"bbox\") for a in anns]), \n","                  \"categories\" : [a.get(\"category_id\") for a in anns]}\n","\n","        if self.transforms:\n","            # Albumentations transforms.\n","            sample = self.transforms(image = image, \n","                                     bboxes = target[\"bboxes\"], \n","                                     labels = target[\"categories\"])\n","            \n","            image = sample[\"image\"].to(torch.float32)\n","            target[\"bboxes\"] = torch.Tensor(sample[\"bboxes\"])\n","\n","        # Normalize the pixel values from [0, 255] to [0, 1]\n","        image = image / 255.0\n","\n","        # As bboxes are in the MS COCO format [x0, y0, w, h], we need to change them to the\n","        # PyTorch format [x0, y0, x1, y1].\n","        target[\"bboxes\"][:, 3] = target[\"bboxes\"][:, 1] + target[\"bboxes\"][:, 3]   \n","        target[\"bboxes\"][:, 2] = target[\"bboxes\"][:, 0] + target[\"bboxes\"][:, 2]\n","        \n","        return image, target\n","\n","    def __len__(self):\n","        return len(self.img_ids)"],"metadata":{"id":"59gn-2M89oi0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bbox_params = {\"format\" : \"coco\", \"label_fields\" : [\"labels\"]}\n","\n","def get_train_transform():\n","    return A.Compose([A.Affine(scale = (0.8, 1.2), translate_percent = 0.1, rotate = (-10, 10), fit_output = True, keep_ratio = True, p = 0.5),\n","                      A.ColorJitter (brightness = 0.1, contrast = 0.1, saturation = 0.1, hue = 0.0, p = 0.5),\n","                      A.GaussianBlur(blur_limit = (3, 7), sigma_limit = 0, p = 0.5),\n","                      A.GaussNoise(var_limit = (10.0, 50.0), mean = 0, per_channel = True, p = 0.5),\n","                      ToTensorV2(p = 1.0)], \n","                      bbox_params = bbox_params)\n","\n","def get_valid_transform():\n","    return A.Compose([ToTensorV2(p = 1.0)], \n","                      bbox_params = bbox_params)\n","\n","def collate_fn(batch):\n","    return tuple(zip(*batch))"],"metadata":{"id":"tL2eejuH9umV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## PyTorch DataLoaders"],"metadata":{"id":"NYNOrO16w-cZ"}},{"cell_type":"code","source":["CLASS_NAME = [\"__background__\", \"person\"]\n","NUM_CLASSES = len(CLASS_NAME)\n","BATCH_SIZE = 8\n","\n","train_dataset = COCO(train_coco, CLASS_NAME[1:], get_train_transform())\n","valid_dataset = COCO(val_coco, CLASS_NAME[1:], get_valid_transform())\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, \n","                                           batch_size = BATCH_SIZE, \n","                                           shuffle = True, \n","                                           collate_fn = collate_fn)\n","\n","valid_loader = torch.utils.data.DataLoader(valid_dataset, \n","                                           batch_size = BATCH_SIZE, \n","                                           shuffle = False,\n","                                           collate_fn = collate_fn)\n","\n","print(\"Train DL: {}, valid DL: {}.\".format(len(train_loader),len(valid_loader)))"],"metadata":{"id":"FWJ15EYw8gms"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Try out the dataloaders to make sure that they are working correctly!\n","\n","x = next(iter(train_loader))\n","i = x[0][0].permute(1, 2, 0).numpy().astype(float)\n","for b in x[1][0][\"bboxes\"]:\n","    cv2.rectangle(i, (int(b[0]), int(b[1])), (int(b[2]), int(b[3])), color = [1, 0, 0])\n","plt.imshow(i)\n","plt.show()"],"metadata":{"id":"KyvNGrTrqTQj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## PyTorch Model Transfer Learning"],"metadata":{"id":"AFYTfcK1xBXX"}},{"cell_type":"code","source":["def unbatch(data, device):\n","    images, targets = data\n","    images = list(image.to(device) for image in images)\n","    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","    return images, targets\n","\n","def train(train_data_loader, model, train_itr, train_loss_list, device):\n","    model.to(device)\n","    model.train()\n","    \n","    print('Training...')\n","    prog_bar = tqdm.tqdm(train_data_loader, total = len(train_data_loader))\n","    for i, data in enumerate(prog_bar):\n","        images, targets = unbatch(data, device)\n","        \n","        optimizer.zero_grad()\n","        loss_dict = model(images, targets)\n","        losses = sum(loss for loss in loss_dict.values())\n","        losses.backward()\n","        optimizer.step()\n","        \n","        loss_value = losses.item()\n","        train_loss_list.append(loss_value)\n","        train_loss_hist.send(loss_value)\n","\n","        train_itr = train_itr + 1\n","        prog_bar.set_description(desc = \"Loss: {:.3f}\".format(loss_value))\n","        \n","    return train_itr, train_loss_list\n","\n","def validate(valid_data_loader, model, val_itr, val_loss_list, device):\n","    model.to(device)\n","    model.train() # Train mode to obtain the loss values.\n","    \n","    print('Validating...')\n","    prog_bar = tqdm.tqdm(valid_data_loader, total = len(valid_data_loader))  \n","    for i, data in enumerate(prog_bar):\n","        images, targets = unbatch(data, device)\n","        \n","        # Remember to set torch.no_grad() to prevent any gradient updates!!!\n","        with torch.no_grad():\n","            optimizer.zero_grad()\n","            loss_dict = model(images, targets)\n","            losses = sum(loss for loss in loss_dict.values())\n","        \n","        loss_value = losses.item()\n","        val_loss_list.append(loss_value)\n","        val_loss_hist.send(loss_value)\n","        \n","        val_itr = val_itr + 1\n","        prog_bar.set_description(desc = \"Loss: {:.3f}\".format(loss_value))\n","        \n","    return val_itr, val_loss_list"],"metadata":{"execution":{"iopub.status.busy":"2023-03-17T03:59:41.174326Z","iopub.execute_input":"2023-03-17T03:59:41.175012Z","iopub.status.idle":"2023-03-17T03:59:41.195208Z","shell.execute_reply.started":"2023-03-17T03:59:41.174972Z","shell.execute_reply":"2023-03-17T03:59:41.194237Z"},"trusted":true,"id":"VrUcgLJjv1ZN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Averager:\n","    def __init__(self):\n","        self.current_total = 0.0\n","        self.iterations = 0.0\n","        \n","    def send(self, value):\n","        self.current_total += value\n","        self.iterations = self.iterations + 1\n","    \n","    @property\n","    def value(self):\n","        if self.iterations == 0:\n","            return 0\n","        else:\n","            return 1.0 * self.current_total / self.iterations\n","    \n","    def reset(self):\n","        self.current_total = 0.0\n","        self.iterations = 0.0"],"metadata":{"execution":{"iopub.status.busy":"2023-03-17T03:59:41.200490Z","iopub.execute_input":"2023-03-17T03:59:41.203520Z","iopub.status.idle":"2023-03-17T03:59:41.212814Z","shell.execute_reply.started":"2023-03-17T03:59:41.203483Z","shell.execute_reply":"2023-03-17T03:59:41.211888Z"},"trusted":true,"id":"TC13Oi7tv1ZN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SaveBestModel:\n","    \"\"\"\n","    Class to save the best model while training. If the current epoch's \n","    validation loss is less than the previous least less, then save the\n","    model state.\n","    \"\"\"\n","    def __init__(self, best_valid_loss = float('inf')):\n","        self.best_valid_loss = best_valid_loss\n","        \n","    def __call__(self, current_valid_loss, epoch, model, optimizer, \n","                 output_file_name = './best_model_{}.pth'.format(date)):\n","        if current_valid_loss < self.best_valid_loss:\n","            self.best_valid_loss = current_valid_loss\n","            \n","            sys.stdout.write(\"\\nBest validation loss: {:.3f} for epoch {}.\\n\".format(self.best_valid_loss, epoch+1));\n","            \n","            torch.save({'epoch': epoch + 1,\n","                        'model_state_dict': model.state_dict(),\n","                        'optimizer_state_dict': optimizer.state_dict()}, \n","                        output_file_name)\n","\n","def save_model(epoch, model, optimizer, \n","               output_file_name = './last_model_{}.pth'.format(date)):\n","    torch.save({'epoch': epoch + 1,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict()}, \n","                output_file_name)"],"metadata":{"execution":{"iopub.status.busy":"2023-03-17T03:59:41.217370Z","iopub.execute_input":"2023-03-17T03:59:41.218175Z","iopub.status.idle":"2023-03-17T03:59:41.232208Z","shell.execute_reply.started":"2023-03-17T03:59:41.218139Z","shell.execute_reply":"2023-03-17T03:59:41.231132Z"},"trusted":true,"id":"xUWbpqY3v1ZO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_fasterrcnn(num_classes):\n","    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights = \"DEFAULT\")\n","    in_features = model.roi_heads.box_predictor.cls_score.in_features\n","    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes) \n","    return model"],"metadata":{"execution":{"iopub.status.busy":"2023-03-17T03:59:41.240053Z","iopub.execute_input":"2023-03-17T03:59:41.242316Z","iopub.status.idle":"2023-03-17T03:59:41.249560Z","shell.execute_reply.started":"2023-03-17T03:59:41.242276Z","shell.execute_reply":"2023-03-17T03:59:41.248420Z"},"trusted":true,"id":"iVq_n17kv1ZO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define FasterRCNN model.\n","model = get_fasterrcnn(num_classes = NUM_CLASSES)\n","\n","params = [p for p in model.parameters() if p.requires_grad]\n","\n","optimizer = torch.optim.SGD(params, lr = 0.001, momentum = 0.9, weight_decay = 0.0005)\n","#optimizer = torch.optim.SGD(params, lr = 0.0001) # For very fine transfer learning.\n","#optimizer = torch.optim.Adam(params, lr = 0.001) # Adam is very slow compared to SGD."],"metadata":{"execution":{"iopub.status.busy":"2023-03-17T09:13:34.835155Z","iopub.execute_input":"2023-03-17T09:13:34.835533Z","iopub.status.idle":"2023-03-17T09:13:35.567838Z","shell.execute_reply.started":"2023-03-17T09:13:34.835497Z","shell.execute_reply":"2023-03-17T09:13:35.566824Z"},"trusted":true,"id":"vIdd_YHrv1ZO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Prepare for training. Containers to hold all sorts of data.\n","train_loss_hist = Averager()\n","val_loss_hist = Averager()\n","train_itr = 1\n","val_itr = 1\n","\n","train_loss_list = []\n","val_loss_list = []\n","\n","save_best_model = SaveBestModel()"],"metadata":{"execution":{"iopub.status.busy":"2023-03-17T09:13:37.172706Z","iopub.execute_input":"2023-03-17T09:13:37.173808Z","iopub.status.idle":"2023-03-17T09:13:37.180304Z","shell.execute_reply.started":"2023-03-17T09:13:37.173768Z","shell.execute_reply":"2023-03-17T09:13:37.178510Z"},"trusted":true,"id":"VzdZ1ppCv1ZO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Number of training epochs.\n","NUM_EPOCHS = 1"],"metadata":{"execution":{"iopub.status.busy":"2023-03-17T09:13:40.065049Z","iopub.execute_input":"2023-03-17T09:13:40.065493Z","iopub.status.idle":"2023-03-17T09:13:40.070700Z","shell.execute_reply.started":"2023-03-17T09:13:40.065450Z","shell.execute_reply":"2023-03-17T09:13:40.069636Z"},"trusted":true,"id":"VqoCwU_Pv1ZP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training-validation iterations.\n","\n","emergency_stop = False # For emergency stopping such as NaN occurence.\n","for epoch in range(NUM_EPOCHS):\n","    print(\"\\nEPOCH {} of {}.\".format(epoch + 1, NUM_EPOCHS));\n","    # Reset the loss history for each iteration.\n","    train_loss_hist.reset()\n","    val_loss_hist.reset()\n","    \n","    # Train loop.\n","    train_loss = train(train_loader, model, train_itr, train_loss_list, device = device_name)\n","    # Validation loop.\n","    val_loss = validate(valid_loader, model, val_itr, val_loss_list, device = device_name)\n","    print(\"Epoch #{} train loss: {:.3f}, validation loss: {:.3f}\".format(epoch + 1, \n","                                                                         train_loss_hist.value, \n","                                                                         val_loss_hist.value));\n","    \n","    # After each iteration, check for NaNs in the model parameters.\n","    # If NaNs exist, stop immediately.\n","    model_parameters = [p.detach().to(torch.device(\"cpu\")).numpy() for p in model.parameters()];\n","    for i in range(len(model_parameters)):\n","        whereisnan = np.where(np.isnan(model_parameters[i]))\n","        lenwhereisnan = [len(w) for w in whereisnan]\n","        if np.sum(lenwhereisnan) > 0:\n","            #print(i, whereisnan[0])\n","            emergency_stop = True\n","            break\n","    if emergency_stop == True:\n","        break\n","    \n","    # If not, save the best model to disk for each iteration.\n","    save_best_model(val_loss_hist.value, epoch, model, optimizer)\n","    save_model(epoch, model, optimizer)"],"metadata":{"execution":{"iopub.status.busy":"2023-03-17T09:13:41.540303Z","iopub.execute_input":"2023-03-17T09:13:41.540766Z","iopub.status.idle":"2023-03-17T10:28:44.866479Z","shell.execute_reply.started":"2023-03-17T09:13:41.540721Z","shell.execute_reply":"2023-03-17T10:28:44.864376Z"},"trusted":true,"id":"Jfez0UMpv1ZP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualizing model outputs.\n","\"\"\"\n","detection_threshold = 0.5\n","data = next(iter(test_loader))\n","\n","images, targets = data\n","images = list(image.to(device_name) for image in images)\n","targets = [{k: v.to(device_name) for k, v in t.items()} for t in targets]\n","model.to(device_name)\n","model.eval()\n","predictions = model(images)\n","\n","for i in range(len(predictions)):\n","    want = predictions[i][\"scores\"] >= detection_threshold\n","    predictions[i][\"boxes\"] = predictions[i][\"boxes\"][want]\n","    predictions[i][\"labels\"] = predictions[i][\"labels\"][want]\n","    predictions[i][\"scores\"] = predictions[i][\"scores\"][want]\n","\"\"\";"],"metadata":{"execution":{"iopub.status.busy":"2023-03-17T10:28:44.874181Z","iopub.execute_input":"2023-03-17T10:28:44.875164Z","iopub.status.idle":"2023-03-17T10:28:44.880583Z","shell.execute_reply.started":"2023-03-17T10:28:44.875121Z","shell.execute_reply":"2023-03-17T10:28:44.879226Z"},"trusted":true,"id":"GRThzo3jv1ZP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","color_picker = [\"k\", \"r\", \"g\", \"b\"]\n","\n","for i, p in zip(images, predictions):\n","    img = i.permute(1, 2, 0).detach().to(torch.device(\"cpu\")).numpy()\n","    fig, ax = plt.subplots(figsize = [3, 3])\n","    ax.imshow(img)\n","    for l, b in zip(p[\"labels\"], p[\"boxes\"]):\n","        b = b.detach().to(torch.device(\"cpu\")).numpy()\n","        l = l.item()\n","        rect = patches.Rectangle(b[:2], (b[2] - b[0]), (b[3] - b[1]), linewidth = 1, \n","                                 edgecolor = color_picker[l], facecolor = \"none\")\n","        ax.add_patch(rect)\n","    plt.show()\n","\"\"\";"],"metadata":{"execution":{"iopub.status.busy":"2023-03-17T10:28:44.881958Z","iopub.execute_input":"2023-03-17T10:28:44.882753Z","iopub.status.idle":"2023-03-17T10:28:44.896753Z","shell.execute_reply.started":"2023-03-17T10:28:44.882712Z","shell.execute_reply":"2023-03-17T10:28:44.896133Z"},"trusted":true,"id":"AS9w33Yyv1ZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test set evaluation.\n","detection_threshold = 0.8\n","\n","#image_list = []\n","prediction_list = []\n","label_list = []\n","\n","losses = []\n","\n","count = 0\n","prog_bar = tqdm.tqdm(test_loader, total = len(test_loader))  \n","for data in prog_bar:\n","    images, targets = data\n","    images = list(image.to(device_name) for image in images)\n","    targets = [{k: v.to(device_name) for k, v in t.items()} for t in targets]\n","    \n","    model.to(device_name)\n","    \n","    model.eval()\n","    output = model(images) # This is a list of dicts, just like targets.\n","    \n","    model.train()\n","    loss_dict = model(images, targets)\n","    batch_loss = sum(loss for loss in loss_dict.values())\n","    losses.append(batch_loss.item())\n","    \n","    if detection_threshold is not None:\n","        for i in range(len(output)):\n","            want = output[i][\"scores\"] >= detection_threshold\n","            output[i][\"boxes\"] = output[i][\"boxes\"][want].detach().to(torch.device(\"cpu\"))\n","            output[i][\"labels\"] = output[i][\"labels\"][want].detach().to(torch.device(\"cpu\"))\n","            output[i][\"scores\"] = output[i][\"scores\"][want].detach().to(torch.device(\"cpu\"))\n","    \n","    #image_list += images # This will cause memory usage to explode!\n","    prediction_list += output\n","    label_list += [{k: v.to(torch.device(\"cpu\")) for k, v in t.items()} for t in targets]\n","    \n","    count = count + 1\n","    \n","    #if count > 0: # For some stupid reason, kernel may crashes after 30 iterations...\n","    #    break\n","    \n","    prog_bar.set_description(desc = \"Current loss: {:.4f}\".format(np.mean(losses)))"],"metadata":{"execution":{"iopub.status.busy":"2023-03-17T10:28:50.680932Z","iopub.execute_input":"2023-03-17T10:28:50.681892Z","iopub.status.idle":"2023-03-17T10:29:52.902688Z","shell.execute_reply.started":"2023-03-17T10:28:50.681822Z","shell.execute_reply":"2023-03-17T10:29:52.901585Z"},"trusted":true,"id":"UKW3Bsy4v1ZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mAP = MeanAveragePrecision()\n","mAP.update(prediction_list, label_list)"],"metadata":{"execution":{"iopub.status.busy":"2023-03-17T10:29:52.904900Z","iopub.execute_input":"2023-03-17T10:29:52.905539Z","iopub.status.idle":"2023-03-17T10:29:52.922544Z","shell.execute_reply.started":"2023-03-17T10:29:52.905498Z","shell.execute_reply":"2023-03-17T10:29:52.921612Z"},"trusted":true,"id":"Np-0CLPfv1ZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sys.stdout.write(\"Mean test loss: {:.3f}.\".format(np.mean(losses)));"],"metadata":{"execution":{"iopub.status.busy":"2023-03-17T10:29:52.923678Z","iopub.execute_input":"2023-03-17T10:29:52.924042Z","iopub.status.idle":"2023-03-17T10:29:52.930216Z","shell.execute_reply.started":"2023-03-17T10:29:52.924004Z","shell.execute_reply":"2023-03-17T10:29:52.929162Z"},"trusted":true,"id":"Zfiqv1m8v1ZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sys.stdout.write(str(mAP.compute()));"],"metadata":{"execution":{"iopub.status.busy":"2023-03-17T10:29:52.932211Z","iopub.execute_input":"2023-03-17T10:29:52.934213Z","iopub.status.idle":"2023-03-17T10:29:58.193419Z","shell.execute_reply.started":"2023-03-17T10:29:52.934174Z","shell.execute_reply":"2023-03-17T10:29:58.192232Z"},"trusted":true,"id":"GPUj5lAMv1ZR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JMF63zdbv1ZR"},"execution_count":null,"outputs":[]}]}