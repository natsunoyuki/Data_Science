{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMJ41vT3uwr741p+8Jmdfa1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# KerasCV Object Detection Training\n","https://keras.io/guides/keras_cv/object_detection_keras_cv/\n","\n","https://www.tensorflow.org/datasets/catalog/voc"],"metadata":{"id":"ElFVoaomCR1z"}},{"cell_type":"code","source":["try:\n","    import keras_core as keras\n","except:\n","    !pip install keras_core\n","    import keras_core as keras\n","\n","try:\n","    import keras_cv\n","except:\n","    !pip -q install keras_cv\n","    import keras_cv\n","\n","import os\n","import resource\n","import tqdm\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","from tensorflow import keras\n","from tensorflow.keras import optimizers\n","\n","from keras_cv import bounding_box\n","from keras_cv import visualization\n","\n","import tensorflow as tf\n","print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n","print(tf.config.list_physical_devices('GPU'))\n","\n","if len(tf.config.list_physical_devices('GPU')) > 0:\n","    device_name = '/GPU:0'\n","else:\n","    device_name = \"/CPU:0\""],"metadata":{"id":"HfxsOo0mCR7S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Transfer Learning"],"metadata":{"id":"AfLIzjW3EHdH"}},{"cell_type":"code","source":["# Dataloaders.\n","\n","def visualize_dataset(inputs, value_range, rows, cols, bounding_box_format):\n","    inputs = next(iter(inputs.take(1)))\n","    images, bounding_boxes = inputs[\"images\"], inputs[\"bounding_boxes\"]\n","    visualization.plot_bounding_box_gallery(\n","        images,\n","        value_range=value_range,\n","        rows=rows,\n","        cols=cols,\n","        y_true=bounding_boxes,\n","        scale=5,\n","        font_scale=0.7,\n","        bounding_box_format=bounding_box_format,\n","        class_mapping=class_mapping,\n","    )\n","\n","\n","def unpackage_raw_tfds_inputs(inputs, bounding_box_format):\n","    image = inputs[\"image\"]\n","    boxes = keras_cv.bounding_box.convert_format(\n","        inputs[\"objects\"][\"bbox\"],\n","        images=image,\n","        source=\"rel_yxyx\",\n","        target=bounding_box_format,\n","    )\n","    bounding_boxes = {\n","        \"classes\": tf.cast(inputs[\"objects\"][\"label\"], dtype=tf.float32),\n","        \"boxes\": tf.cast(boxes, dtype=tf.float32),\n","    }\n","    return {\"images\": tf.cast(image, tf.float32), \"bounding_boxes\": bounding_boxes}\n","\n","\n","def load_pascal_voc(split, dataset, bounding_box_format):\n","    # https://www.tensorflow.org/datasets/catalog/voc\n","    ds = tfds.load(dataset, split=split, with_info=False, shuffle_files=True)\n","    ds = ds.map(\n","        lambda x: unpackage_raw_tfds_inputs(x, bounding_box_format=bounding_box_format),\n","        num_parallel_calls=tf.data.AUTOTUNE,\n","    )\n","    return ds"],"metadata":{"id":"Q-bx948OEJfV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Pascal VOC classes.\n","\n","class_ids = [\n","    \"Aeroplane\",\n","    \"Bicycle\",\n","    \"Bird\",\n","    \"Boat\",\n","    \"Bottle\",\n","    \"Bus\",\n","    \"Car\",\n","    \"Cat\",\n","    \"Chair\",\n","    \"Cow\",\n","    \"Dining Table\",\n","    \"Dog\",\n","    \"Horse\",\n","    \"Motorbike\",\n","    \"Person\",\n","    \"Potted Plant\",\n","    \"Sheep\",\n","    \"Sofa\",\n","    \"Train\",\n","    \"Tvmonitor\",\n","    \"Total\",\n","]\n","class_mapping = dict(zip(range(len(class_ids)), class_ids))"],"metadata":{"id":"YTrW6s4K8LrT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BATCH_SIZE = 8\n","\n","\n","train_ds = load_pascal_voc(\n","    split=\"train\", dataset=\"voc/2007\", bounding_box_format=\"xywh\"\n",")\n","\n","eval_ds = load_pascal_voc(\n","    split=\"validation\", dataset=\"voc/2007\", bounding_box_format=\"xywh\"\n",")\n","\n","train_ds = train_ds.shuffle(BATCH_SIZE * 4)\n","\n","train_ds = train_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)\n","eval_ds = eval_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)"],"metadata":{"id":"b4IHhpl08IJp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Train dataset length: {}.\".format(len(train_ds)))\n","print(\"Evaluation dataset length: {}\".format(len(eval_ds)))"],"metadata":{"id":"5SUZx1Wk3tMt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","visualize_dataset(\n","    train_ds, bounding_box_format=\"xywh\", value_range=(0, 255), rows=2, cols=2\n",")\n","\"\"\";"],"metadata":{"id":"wrN4eKvYEON2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","visualize_dataset(\n","    eval_ds,\n","    bounding_box_format=\"xywh\",\n","    value_range=(0, 255),\n","    rows=2,\n","    cols=2,\n","    # If you are not running your experiment on a local machine, you can also\n","    # make `visualize_dataset()` dump the plot to a file using `path`:\n","    # path=\"eval.png\"\n",")\n","\"\"\";"],"metadata":{"id":"Cjj7-x5jEShM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Image augmentation for training.\n","\n","augmenter = keras.Sequential(\n","    layers=[\n","        keras_cv.layers.RandomFlip(mode=\"horizontal\", bounding_box_format=\"xywh\"),\n","        keras_cv.layers.JitteredResize(\n","            target_size=(640, 640), scale_factor=(0.75, 1.3), bounding_box_format=\"xywh\"\n","        ),\n","    ]\n",")\n","\n","train_ds = train_ds.map(augmenter, num_parallel_calls=tf.data.AUTOTUNE)\n","\n","\"\"\"\n","visualize_dataset(\n","    train_ds, bounding_box_format=\"xywh\", value_range=(0, 255), rows=2, cols=2\n",")\n","\"\"\";"],"metadata":{"id":"AwrftOZlEUnU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inference_resizing = keras_cv.layers.Resizing(\n","    640, 640, bounding_box_format=\"xywh\", pad_to_aspect_ratio=True\n",")\n","\n","eval_ds = eval_ds.map(inference_resizing, num_parallel_calls=tf.data.AUTOTUNE)\n","\n","\"\"\"\n","visualize_dataset(\n","    eval_ds, bounding_box_format=\"xywh\", value_range=(0, 255), rows=2, cols=2\n",")\n","\"\"\";"],"metadata":{"id":"FAT1WNU7EaMq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Unpackage inputs from preprocessing to feed into the model.\n","\n","def dict_to_tuple(inputs):\n","    return inputs[\"images\"], bounding_box.to_dense(\n","        inputs[\"bounding_boxes\"], max_boxes=32\n","    )\n","\n","with tf.device(device_name):\n","    train_ds = train_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n","    eval_ds = eval_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n","\n","    train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n","    eval_ds = eval_ds.prefetch(tf.data.AUTOTUNE)"],"metadata":{"id":"9oU8Iq2uEevM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Metrics.\n","\n","coco_metrics = keras_cv.metrics.BoxCOCOMetrics(\n","    bounding_box_format=\"xywh\", evaluate_freq=20\n",")"],"metadata":{"id":"_833EIILHSfL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def print_metrics(metrics, result):\n","    maxlen = max([len(key) for key in result.keys()])\n","    print(\"Metrics:\")\n","    print(\"-\" * (maxlen + 1))\n","    for k, v in metrics.items():\n","        print(f\"{k.ljust(maxlen+1)}: {v.numpy():0.2f}\")"],"metadata":{"id":"P0EzofmmHUbA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#pretrained_model.compile(\n","#    classification_loss=\"focal\",\n","#    box_loss=\"smoothl1\",\n","#    optimizer=optimizer,\n","#    metrics=[coco_metrics],\n","#)\n","#coco_metrics.reset_state()\n","#result = pretrained_model.evaluate(eval_ds.take(40), verbose=0)\n","#result = coco_metrics.result(force=True)\n","\n","#print_metrics(result)"],"metadata":{"id":"FpVF-1GlHWLW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class EvaluateCOCOMetricsCallback(keras.callbacks.Callback):\n","    def __init__(self, data):\n","        super().__init__()\n","        self.data = data\n","        self.metrics = keras_cv.metrics.BoxCOCOMetrics(\n","            bounding_box_format=\"xywh\",\n","            # passing 1e9 ensures we never evaluate until\n","            # `metrics.result(force=True)` is\n","            # called.\n","            evaluate_freq=1e9,\n","        )\n","\n","    def on_epoch_end(self, epoch, logs):\n","        self.metrics.reset_state()\n","        for batch in tqdm.tqdm(self.data):\n","            images, y_true = batch[0], batch[1]\n","            y_pred = self.model.predict(images, verbose=0)\n","            self.metrics.update_state(y_true, y_pred)\n","\n","        metrics = self.metrics.result(force=True)\n","        logs.update(metrics)\n","        return logs"],"metadata":{"id":"OT0SW99tHZ58"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Prepare optimizer.\n","\n","base_lr = 0.005\n","\n","# Including a global_clipnorm is extremely important in object detection tasks\n","optimizer = tf.keras.optimizers.SGD(\n","    learning_rate=base_lr, momentum=0.9, global_clipnorm=10.0\n",")"],"metadata":{"id":"hbkF2dtTYFhx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# https://keras.io/api/keras_cv/models/\n","\n","model = \"yolo\"\n","\n","#preset = \"resnet50_imagenet\"\n","preset = \"yolo_v8_xs_backbone_coco\"\n","\n","with tf.device(device_name):\n","    if model == \"retinanet\":\n","        model = keras_cv.models.RetinaNet.from_preset(\n","            preset,\n","            num_classes=len(class_mapping),\n","            bounding_box_format=\"xywh\",\n","        )\n","\n","        classification_loss = \"focal\"\n","        box_loss = \"smoothl1\"\n","\n","    elif model == \"yolo\":\n","        model = keras_cv.models.YOLOV8Detector.from_preset(\n","            preset,\n","            num_classes=len(class_mapping),\n","            bounding_box_format=\"xywh\",\n","        )\n","\n","        classification_loss = 'binary_crossentropy'\n","        box_loss = 'ciou'\n","\n","    # Compile model on device.\n","    model.compile(\n","        classification_loss=classification_loss,\n","        box_loss=box_loss,\n","        optimizer=optimizer,\n","        jit_compile=False,\n","    )"],"metadata":{"id":"dRiQk_S3HaMj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#print(model.backbone.summary())"],"metadata":{"id":"4FFf_O2RZaUT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 10\n","\n","with tf.device(device_name):\n","    history = model.fit(\n","        train_ds,\n","        validation_data=eval_ds,\n","        epochs=epochs,\n","        #callbacks=[EvaluateCOCOMetricsCallback(eval_ds)],\n","    )"],"metadata":{"id":"zpKlv2JtHh1M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history.history"],"metadata":{"id":"8Uh_ir-LXqNO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jGmyBx8SsxwA"},"execution_count":null,"outputs":[]}]}