{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN9/TYbBsxq36B0pvOrxMK7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# KerasCV Object Detection Training\n","https://keras.io/guides/keras_cv/object_detection_keras_cv/\n","\n","https://www.tensorflow.org/datasets/catalog/voc"],"metadata":{"id":"ElFVoaomCR1z"}},{"cell_type":"code","source":["try:\n","    import keras_core as keras\n","except:\n","    !pip -q install keras_core\n","    import keras_core as keras\n","\n","try:\n","    import keras_cv\n","except:\n","    !pip -q install keras_cv\n","    import keras_cv\n","\n","import os\n","import resource\n","import tqdm\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import optimizers\n","\n","import tensorflow_datasets as tfds\n","\n","from keras_cv import bounding_box\n","from keras_cv import visualization\n","\n","import tensorflow as tf\n","print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n","print(tf.config.list_physical_devices('GPU'))\n","\n","if len(tf.config.list_physical_devices('GPU')) > 0:\n","    device_name = '/GPU:0'\n","else:\n","    device_name = \"/CPU:0\""],"metadata":{"id":"HfxsOo0mCR7S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Transfer Learning"],"metadata":{"id":"AfLIzjW3EHdH"}},{"cell_type":"code","source":["# Dataloaders.\n","\n","def visualize_dataset(inputs, value_range, rows, cols, bounding_box_format):\n","    inputs = next(iter(inputs.take(1)))\n","    images, bounding_boxes = inputs[\"images\"], inputs[\"bounding_boxes\"]\n","    visualization.plot_bounding_box_gallery(\n","        images,\n","        value_range=value_range,\n","        rows=rows,\n","        cols=cols,\n","        y_true=bounding_boxes,\n","        scale=5,\n","        font_scale=0.7,\n","        bounding_box_format=bounding_box_format,\n","        class_mapping=class_mapping,\n","    )\n","\n","\n","def unpackage_raw_tfds_inputs(inputs, bounding_box_format):\n","    image = inputs[\"image\"]\n","    boxes = keras_cv.bounding_box.convert_format(\n","        inputs[\"objects\"][\"bbox\"],\n","        images=image,\n","        source=\"rel_yxyx\",\n","        target=bounding_box_format,\n","    )\n","    bounding_boxes = {\n","        \"classes\": tf.cast(inputs[\"objects\"][\"label\"], dtype=tf.float32),\n","        \"boxes\": tf.cast(boxes, dtype=tf.float32),\n","    }\n","    return {\"images\": tf.cast(image, tf.float32), \"bounding_boxes\": bounding_boxes}\n","\n","\n","def load_pascal_voc(split, dataset, bounding_box_format):\n","    # https://www.tensorflow.org/datasets/catalog/voc\n","    ds = tfds.load(dataset, split=split, with_info=False, shuffle_files=True)\n","    ds = ds.map(\n","        lambda x: unpackage_raw_tfds_inputs(x, bounding_box_format=bounding_box_format),\n","        num_parallel_calls=tf.data.AUTOTUNE,\n","    )\n","    return ds"],"metadata":{"id":"Q-bx948OEJfV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Pascal VOC classes.\n","\n","class_ids = [\n","    \"Aeroplane\",\n","    \"Bicycle\",\n","    \"Bird\",\n","    \"Boat\",\n","    \"Bottle\",\n","    \"Bus\",\n","    \"Car\",\n","    \"Cat\",\n","    \"Chair\",\n","    \"Cow\",\n","    \"Dining Table\",\n","    \"Dog\",\n","    \"Horse\",\n","    \"Motorbike\",\n","    \"Person\",\n","    \"Potted Plant\",\n","    \"Sheep\",\n","    \"Sofa\",\n","    \"Train\",\n","    \"Tvmonitor\",\n","    \"Total\",\n","]\n","\n","class_mapping = dict(zip(range(len(class_ids)), class_ids))"],"metadata":{"id":"YTrW6s4K8LrT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BATCH_SIZE = 8\n","\n","\n","train_ds = load_pascal_voc(\n","    split=\"train\", dataset=\"voc/2007\", bounding_box_format=\"xywh\"\n",")\n","\n","eval_ds = load_pascal_voc(\n","    split=\"validation\", dataset=\"voc/2007\", bounding_box_format=\"xywh\"\n",")\n","\n","train_ds = train_ds.shuffle(BATCH_SIZE * 4)\n","\n","train_ds = train_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)\n","eval_ds = eval_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)"],"metadata":{"id":"b4IHhpl08IJp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Train dataset length: {}.\".format(len(train_ds)))\n","print(\"Evaluation dataset length: {}\".format(len(eval_ds)))"],"metadata":{"id":"5SUZx1Wk3tMt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","visualize_dataset(\n","    train_ds, bounding_box_format=\"xywh\", value_range=(0, 255), rows=2, cols=2\n",")\n","\"\"\";"],"metadata":{"id":"wrN4eKvYEON2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","visualize_dataset(\n","    eval_ds,\n","    bounding_box_format=\"xywh\",\n","    value_range=(0, 255),\n","    rows=2,\n","    cols=2,\n","    # If you are not running your experiment on a local machine, you can also\n","    # make `visualize_dataset()` dump the plot to a file using `path`:\n","    # path=\"eval.png\"\n",")\n","\"\"\";"],"metadata":{"id":"Cjj7-x5jEShM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Image augmentation for training.\n","\n","augmenter = keras.Sequential(\n","    layers=[\n","        keras_cv.layers.RandomFlip(mode=\"horizontal\", bounding_box_format=\"xywh\"),\n","        keras_cv.layers.JitteredResize(\n","            target_size=(640, 640), scale_factor=(0.75, 1.3), bounding_box_format=\"xywh\"\n","        ),\n","    ]\n",")\n","\n","train_ds = train_ds.map(augmenter, num_parallel_calls = tf.data.AUTOTUNE)\n","\n","\"\"\"\n","visualize_dataset(\n","    train_ds, bounding_box_format=\"xywh\", value_range=(0, 255), rows=2, cols=2\n",")\n","\"\"\";"],"metadata":{"id":"AwrftOZlEUnU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inference_resizing = keras_cv.layers.Resizing(\n","    640, 640, bounding_box_format=\"xywh\", pad_to_aspect_ratio=True\n",")\n","\n","eval_ds = eval_ds.map(inference_resizing, num_parallel_calls = tf.data.AUTOTUNE)\n","\n","\"\"\"\n","visualize_dataset(\n","    eval_ds, bounding_box_format=\"xywh\", value_range=(0, 255), rows=2, cols=2\n",")\n","\"\"\";"],"metadata":{"id":"FAT1WNU7EaMq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Unpackage inputs from preprocessing to feed into the model.\n","\n","def dict_to_tuple(inputs):\n","    return inputs[\"images\"], bounding_box.to_dense(\n","        inputs[\"bounding_boxes\"], max_boxes = 32\n","    )\n","\n","with tf.device(device_name):\n","    train_ds = train_ds.map(dict_to_tuple, num_parallel_calls = tf.data.AUTOTUNE)\n","    eval_ds = eval_ds.map(dict_to_tuple, num_parallel_calls = tf.data.AUTOTUNE)\n","\n","    train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n","    eval_ds = eval_ds.prefetch(tf.data.AUTOTUNE)"],"metadata":{"id":"9oU8Iq2uEevM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Prepare optimizer.\n","\n","base_lr = 0.005\n","\n","# Including a global_clipnorm is extremely important in object detection tasks\n","optimizer = tf.keras.optimizers.SGD(\n","    learning_rate = base_lr, momentum = 0.9, global_clipnorm = 10.0\n",")"],"metadata":{"id":"hbkF2dtTYFhx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# https://keras.io/api/keras_cv/models/\n","\n","#model = \"retinanet\"\n","model = \"yolo\"\n","\n","#preset = \"resnet50_imagenet\"\n","preset = \"yolo_v8_xs_backbone_coco\"\n","\n","with tf.device(device_name):\n","    if model == \"retinanet\":\n","        model = keras_cv.models.RetinaNet.from_preset(\n","            preset,\n","            num_classes = len(class_mapping),\n","            bounding_box_format = \"xywh\",\n","        )\n","\n","        classification_loss = \"focal\"\n","        box_loss = \"smoothl1\"\n","\n","    elif model == \"yolo\":\n","        model = keras_cv.models.YOLOV8Detector.from_preset(\n","            preset,\n","            num_classes = len(class_mapping),\n","            bounding_box_format = \"xywh\",\n","        )\n","\n","        classification_loss = 'binary_crossentropy'\n","        box_loss = 'ciou'\n","\n","    # Compile model on device.\n","    model.compile(\n","        classification_loss = classification_loss,\n","        box_loss = box_loss,\n","        optimizer = optimizer,\n","        jit_compile = False,\n","    )"],"metadata":{"id":"dRiQk_S3HaMj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#print(model.backbone.summary())"],"metadata":{"id":"4FFf_O2RZaUT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 10\n","\n","with tf.device(device_name):\n","    history = model.fit(\n","        train_ds,\n","        validation_data = eval_ds,\n","        epochs = epochs,\n","    )"],"metadata":{"id":"zpKlv2JtHh1M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize = (15, 3))\n","plt.subplot(1, 3, 1)\n","plt.plot([i + 1 for i in history.epoch], history.history[\"loss\"], \"-o\")\n","plt.plot([i + 1 for i in history.epoch], history.history[\"val_loss\"], \"-o\")\n","plt.grid(True)\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend([\"Loss\", \"Val loss\"])\n","plt.subplot(1, 3, 2)\n","plt.plot([i + 1 for i in history.epoch], history.history[\"box_loss\"], \"-o\")\n","plt.plot([i + 1 for i in history.epoch], history.history[\"val_box_loss\"], \"-o\")\n","plt.grid(True)\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Box Loss\")\n","plt.legend([\"Box loss\", \"Val box loss\"])\n","plt.subplot(1, 3, 3)\n","plt.plot([i + 1 for i in history.epoch], history.history[\"class_loss\"], \"-o\")\n","plt.plot([i + 1 for i in history.epoch], history.history[\"val_class_loss\"], \"-o\")\n","plt.grid(True)\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Class Loss\")\n","plt.legend([\"Class loss\", \"Val class loss\"])\n","plt.show()"],"metadata":{"id":"8Uh_ir-LXqNO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evaluation_results = model.evaluate(eval_ds, return_dict = True)\n","\n","evaluation_results"],"metadata":{"id":"0qbaJELCmxJl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate metrics on the trained model using eval_ds.\n","\n","coco_metrics = keras_cv.metrics.BoxCOCOMetrics(\n","    bounding_box_format=\"xywh\", evaluate_freq=1\n",")\n","\n","coco_metrics.reset_state()\n","\n","for batch in tqdm.tqdm(eval_ds):\n","    x, y = batch\n","\n","    with tf.device(device_name):\n","        y_pred = model.predict(x, verbose = False)\n","\n","    coco_metrics.update_state(y, y_pred)\n","\n","metrics_result = coco_metrics.result(force = True)"],"metadata":{"id":"-NNbEIGDekuv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["metrics_result"],"metadata":{"id":"_yKIfOOtlrYz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x, y = next(iter(eval_ds))\n","\n","y_pred = model.predict(x)\n","\n","visualization.plot_bounding_box_gallery(\n","    x,\n","    value_range = (0, 255),\n","    rows = 2,\n","    cols = 4,\n","    y_pred = y_pred,\n","    scale = 5,\n","    font_scale = 0.7,\n","    bounding_box_format = \"xywh\",\n","    class_mapping = class_mapping,\n",")"],"metadata":{"id":"d5GFNXm1l2_j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Mhl6ftB-mNni"},"execution_count":null,"outputs":[]}]}